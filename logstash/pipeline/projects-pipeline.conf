# Logstash Pipeline: Projects
# Syncs Project data from PostgreSQL to Elasticsearch

input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/drivers/postgresql-42.7.1.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}"
    jdbc_user => "${POSTGRES_USER}"
    jdbc_password => "${POSTGRES_PASSWORD}"

    # Run every 30 seconds for near real-time sync
    schedule => "*/30 * * * * *"

    # Track last sync to only get updates
    use_column_value => true
    tracking_column => "updated_at"
    tracking_column_type => "timestamp"
    last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run_projects"

    # SQL Query with related data
    statement => "
      SELECT
        p.id,
        p.account_id,
        a.name as account_name,
        a.territory_id,
        t.name as territory_name,
        p.name,
        p.status,
        p.start_date,
        p.end_date,
        p.type,
        p.attributes,
        p.created_at,
        p.updated_at,
        COUNT(DISTINCT ak.pragmatic_id) as total_pragmatics,
        COUNT(DISTINCT ak.knowledge_id) as total_knowledge_applied
      FROM \"Project\" p
      INNER JOIN \"Account\" a ON p.account_id = a.id
      LEFT JOIN \"territory\" t ON a.territory_id = t.id
      LEFT JOIN \"Applied_Knowledge\" ak ON ak.project_id = p.id
      WHERE p.updated_at > :sql_last_value
      GROUP BY p.id, a.name, a.territory_id, t.name
      ORDER BY p.updated_at ASC
    "

    clean_run => false
    lowercase_column_names => false
  }
}

filter {
  # Parse JSON attributes if present
  if [attributes] {
    json {
      source => "attributes"
      target => "attributes_parsed"
      skip_on_invalid_json => true
    }
  }

  # Calculate project duration in days
  if [start_date] and [end_date] {
    ruby {
      code => "
        start_date = event.get('start_date')
        end_date = event.get('end_date')
        if start_date && end_date
          duration = (Date.parse(end_date) - Date.parse(start_date)).to_i
          event.set('duration_days', duration)
        end
      "
    }
  }

  # Calculate if project is active
  ruby {
    code => "
      status = event.get('status')
      end_date = event.get('end_date')
      is_active = status == 'Active' && (end_date.nil? || Date.parse(end_date) >= Date.today)
      event.set('is_currently_active', is_active)
    "
  }

  # Add metadata
  mutate {
    add_field => {
      "[@metadata][index]" => "projects"
      "[@metadata][document_id]" => "%{id}"
      "entity_type" => "project"
      "sync_timestamp" => "%{@timestamp}"
    }
    remove_field => ["@version"]
  }

  # Convert timestamps
  date {
    match => ["created_at", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS"]
    target => "created_at"
  }

  date {
    match => ["updated_at", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS"]
    target => "updated_at"
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS}"]
    index => "projects-%{+YYYY.MM}"
    document_id => "%{[@metadata][document_id]}"
    action => "index"
  }

  # Debug output (optional)
  stdout {
    codec => rubydebug {
      metadata => false
    }
  }
}
